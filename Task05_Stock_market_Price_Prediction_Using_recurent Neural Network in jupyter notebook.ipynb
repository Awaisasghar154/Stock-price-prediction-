{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpAuMVCwfWs8"
   },
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxJfRe4bfYVA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir9zwETrfbrp"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ZT1f24vHffuf"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQ47JAxrgmaL"
   },
   "source": [
    "### Importing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1xiv3pJOgqY3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325.25],\n",
       "       [331.27],\n",
       "       [329.83],\n",
       "       ...,\n",
       "       [793.7 ],\n",
       "       [783.33],\n",
       "       [782.75]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "training_set = dataset_train.iloc[:, 1:2].values\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HT8_2UJegtG5"
   },
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OTrF2kR7gx9x"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "# Use Normalization (versus Standardization) for RNNs with Sigmoid Activation Functions\n",
    "# 'MinMaxScalar' is a Normalization Library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 'feature_range = (0,1)' makes sure that training data is scaled to have values between 0 and 1\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyYgYocqhNUg"
   },
   "source": [
    "### Creating a data structure with 60 timesteps and 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iofU21B0i6ST"
   },
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps (look back 60 days) and 1 output\n",
    "# This tells the RNN what to remember (Number of timesteps) when predicting the next Stock Price\n",
    "# The wrong number of timesteps can lead to Overfitting or bogus results\n",
    "# 'x_train' Input with 60 previous days' stock prices\n",
    "X_train = []\n",
    "# 'y_train' Output with next day's stock price\n",
    "y_train = []\n",
    "for i in range(60, 1258):\n",
    "    X_train.append(training_set_scaled[i-60:i, 0])\n",
    "    y_train.append(training_set_scaled[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8yaN7Zvi95l"
   },
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "FOXqJHmNjBkz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2012</td>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2012</td>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2012</td>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/9/2012</td>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>12/23/2016</td>\n",
       "      <td>790.90</td>\n",
       "      <td>792.74</td>\n",
       "      <td>787.28</td>\n",
       "      <td>789.91</td>\n",
       "      <td>623,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>12/27/2016</td>\n",
       "      <td>790.68</td>\n",
       "      <td>797.86</td>\n",
       "      <td>787.66</td>\n",
       "      <td>791.55</td>\n",
       "      <td>789,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>12/28/2016</td>\n",
       "      <td>793.70</td>\n",
       "      <td>794.23</td>\n",
       "      <td>783.20</td>\n",
       "      <td>785.05</td>\n",
       "      <td>1,153,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>12/29/2016</td>\n",
       "      <td>783.33</td>\n",
       "      <td>785.93</td>\n",
       "      <td>778.92</td>\n",
       "      <td>782.79</td>\n",
       "      <td>744,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>12/30/2016</td>\n",
       "      <td>782.75</td>\n",
       "      <td>782.78</td>\n",
       "      <td>770.41</td>\n",
       "      <td>771.82</td>\n",
       "      <td>1,770,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low   Close      Volume\n",
       "0       1/3/2012  325.25  332.83  324.97  663.59   7,380,500\n",
       "1       1/4/2012  331.27  333.87  329.08  666.45   5,749,400\n",
       "2       1/5/2012  329.83  330.75  326.89  657.21   6,590,300\n",
       "3       1/6/2012  328.34  328.77  323.68  648.24   5,405,900\n",
       "4       1/9/2012  322.04  322.29  309.46  620.76  11,688,800\n",
       "...          ...     ...     ...     ...     ...         ...\n",
       "1253  12/23/2016  790.90  792.74  787.28  789.91     623,400\n",
       "1254  12/27/2016  790.68  797.86  787.66  791.55     789,100\n",
       "1255  12/28/2016  793.70  794.23  783.20  785.05   1,153,800\n",
       "1256  12/29/2016  783.33  785.93  778.92  782.79     744,300\n",
       "1257  12/30/2016  782.75  782.78  770.41  771.82   1,770,000\n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshaping (add more dimensions)\n",
    "# This lets you add more indicators that may potentially have corelation with Stock Prices\n",
    "# Keras RNNs expects an input shape (Batch Size, Timesteps, input_dim)\n",
    "# '.shape[0]' is the number of Rows (Batch Size)\n",
    "# '.shape[1]' is the number of Columns (timesteps)\n",
    "# 'input_dim' is the number of factors that may affect stock prices\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Show the dataset we're working with\n",
    "display(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRRSOJeVjEWV"
   },
   "source": [
    "## Part 2 - Building and Training the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4XV88JMjHXG"
   },
   "source": [
    "### Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1676414787940,
     "user": {
      "displayName": "jayesh soni",
      "userId": "15631968598906199091"
     },
     "user_tz": 300
    },
    "id": "9JRnqsxEjKsD"
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEIE-1s9jNzC"
   },
   "source": [
    "### Initialising the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1338dJ0UjRKH"
   },
   "outputs": [],
   "source": [
    "# Initialising the RNN\n",
    "# Regression is when you predict a continuous value\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62eg1OPGjT8z"
   },
   "source": [
    "### Adding the first LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2hIinyXUjbVU"
   },
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "# 'units' is the number of LSTM Memory Cells (Neurons) for higher dimensionality\n",
    "# 'return_sequences = True' because we will add more stacked LSTM Layers\n",
    "# 'input_shape' of x_train\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "# 20% of Neurons will be ignored (10 out of 50 Neurons) to prevent Overfitting\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XBIYLyOjlMx"
   },
   "source": [
    "### Adding a second LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "UG7nrVaSjuZ2"
   },
   "outputs": [],
   "source": [
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "# Not need to specify input_shape for second Layer, it knows that we have 50 Neurons from the previous layer\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey3fHVnGj1cu"
   },
   "source": [
    "### Adding a third LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PuNi6PgFj7jO"
   },
   "outputs": [],
   "source": [
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYTrtfTmj933"
   },
   "source": [
    "### Adding a fourth LSTM layer and some Dropout regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Jp4Ty8fRkBYV"
   },
   "outputs": [],
   "source": [
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "# This is the last LSTM Layer. 'return_sequences = false' by default so we leave it out.\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ABI6rOIkHhk"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "aM6R1z4WkME8"
   },
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "# 'units = 1' because Output layer has one dimension\n",
    "regressor.add(Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLx4K7uUkPSh"
   },
   "source": [
    "### Compiling the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XTrhVN-tkbko"
   },
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "# Keras documentation recommends 'RMSprop' as a good optimizer for RNNs\n",
    "# Trial and error suggests that 'adam' optimizer is a good choice\n",
    "# loss = 'mean_squared_error' which is good for Regression vs. 'Binary Cross Entropy' previously used for Classification\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mPhwKGkkebi"
   },
   "source": [
    "### Fitting the RNN to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 175,
     "status": "ok",
     "timestamp": 1676414788110,
     "user": {
      "displayName": "jayesh soni",
      "userId": "15631968598906199091"
     },
     "user_tz": 300
    },
    "id": "I06Nkrz5kkb-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "38/38 [==============================] - 8s 45ms/step - loss: 0.0345\n",
      "Epoch 2/200\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.0068\n",
      "Epoch 3/200\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.0052\n",
      "Epoch 4/200\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.0052\n",
      "Epoch 5/200\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.0053\n",
      "Epoch 6/200\n",
      "38/38 [==============================] - 2s 45ms/step - loss: 0.0052\n",
      "Epoch 7/200\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.0050\n",
      "Epoch 8/200\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.0048\n",
      "Epoch 9/200\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.0049\n",
      "Epoch 10/200\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.0045\n",
      "Epoch 11/200\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.0046\n",
      "Epoch 12/200\n",
      "38/38 [==============================] - 2s 46ms/step - loss: 0.0040\n",
      "Epoch 13/200\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.0044\n",
      "Epoch 14/200\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.0040\n",
      "Epoch 15/200\n",
      "38/38 [==============================] - 2s 47ms/step - loss: 0.0041\n",
      "Epoch 16/200\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.0040\n",
      "Epoch 17/200\n",
      "38/38 [==============================] - 2s 49ms/step - loss: 0.0040\n",
      "Epoch 18/200\n",
      "38/38 [==============================] - 2s 49ms/step - loss: 0.0039\n",
      "Epoch 19/200\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.0042\n",
      "Epoch 20/200\n",
      "38/38 [==============================] - 2s 48ms/step - loss: 0.0034\n",
      "Epoch 21/200\n",
      "38/38 [==============================] - 2s 49ms/step - loss: 0.0032\n",
      "Epoch 22/200\n",
      "38/38 [==============================] - 2s 50ms/step - loss: 0.0032\n",
      "Epoch 23/200\n",
      "38/38 [==============================] - 2s 50ms/step - loss: 0.0035\n",
      "Epoch 24/200\n",
      "38/38 [==============================] - 2s 51ms/step - loss: 0.0037\n",
      "Epoch 25/200\n",
      "38/38 [==============================] - 2s 49ms/step - loss: 0.0032\n",
      "Epoch 26/200\n",
      "38/38 [==============================] - 2s 50ms/step - loss: 0.0030\n",
      "Epoch 27/200\n",
      "38/38 [==============================] - 2s 51ms/step - loss: 0.0029\n",
      "Epoch 28/200\n",
      "38/38 [==============================] - 2s 51ms/step - loss: 0.0030\n",
      "Epoch 29/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0026\n",
      "Epoch 30/200\n",
      "38/38 [==============================] - 2s 61ms/step - loss: 0.0032\n",
      "Epoch 31/200\n",
      "38/38 [==============================] - 3s 85ms/step - loss: 0.0029\n",
      "Epoch 32/200\n",
      "38/38 [==============================] - 3s 90ms/step - loss: 0.0028\n",
      "Epoch 33/200\n",
      "38/38 [==============================] - 4s 94ms/step - loss: 0.0030\n",
      "Epoch 34/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0026\n",
      "Epoch 35/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0029\n",
      "Epoch 36/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0025\n",
      "Epoch 37/200\n",
      "38/38 [==============================] - 2s 51ms/step - loss: 0.0026\n",
      "Epoch 38/200\n",
      "38/38 [==============================] - 2s 51ms/step - loss: 0.0028\n",
      "Epoch 39/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0027\n",
      "Epoch 40/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0026\n",
      "Epoch 41/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0025\n",
      "Epoch 42/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0029\n",
      "Epoch 43/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0026\n",
      "Epoch 44/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0023\n",
      "Epoch 45/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0023\n",
      "Epoch 46/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0023\n",
      "Epoch 47/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0029\n",
      "Epoch 48/200\n",
      "38/38 [==============================] - 2s 51ms/step - loss: 0.0025\n",
      "Epoch 49/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0029\n",
      "Epoch 50/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0023\n",
      "Epoch 51/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0022\n",
      "Epoch 52/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0022\n",
      "Epoch 53/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0022\n",
      "Epoch 54/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0021\n",
      "Epoch 55/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0022\n",
      "Epoch 56/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0024\n",
      "Epoch 57/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0021\n",
      "Epoch 58/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0020\n",
      "Epoch 59/200\n",
      "38/38 [==============================] - 3s 67ms/step - loss: 0.0021\n",
      "Epoch 60/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0025\n",
      "Epoch 61/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0020\n",
      "Epoch 62/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0021\n",
      "Epoch 63/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0019\n",
      "Epoch 64/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0020\n",
      "Epoch 65/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0018\n",
      "Epoch 66/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0019\n",
      "Epoch 67/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0019\n",
      "Epoch 68/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0018\n",
      "Epoch 69/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0017\n",
      "Epoch 70/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0019\n",
      "Epoch 71/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0019\n",
      "Epoch 72/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0019\n",
      "Epoch 73/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0021\n",
      "Epoch 74/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0021\n",
      "Epoch 75/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0020\n",
      "Epoch 76/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0018\n",
      "Epoch 77/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0017\n",
      "Epoch 78/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0015\n",
      "Epoch 79/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0020\n",
      "Epoch 80/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0016\n",
      "Epoch 81/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0018\n",
      "Epoch 82/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0015\n",
      "Epoch 83/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0018\n",
      "Epoch 84/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0018\n",
      "Epoch 85/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0016\n",
      "Epoch 86/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0015\n",
      "Epoch 87/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0018\n",
      "Epoch 88/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0017\n",
      "Epoch 89/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0015\n",
      "Epoch 90/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0015\n",
      "Epoch 91/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0013\n",
      "Epoch 92/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0017\n",
      "Epoch 93/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0015\n",
      "Epoch 94/200\n",
      "38/38 [==============================] - 2s 59ms/step - loss: 0.0014\n",
      "Epoch 95/200\n",
      "38/38 [==============================] - 2s 60ms/step - loss: 0.0016\n",
      "Epoch 96/200\n",
      "38/38 [==============================] - 2s 60ms/step - loss: 0.0013\n",
      "Epoch 97/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0014\n",
      "Epoch 98/200\n",
      "38/38 [==============================] - 2s 59ms/step - loss: 0.0015\n",
      "Epoch 99/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0014\n",
      "Epoch 100/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0014\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0013\n",
      "Epoch 102/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0015\n",
      "Epoch 103/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0015\n",
      "Epoch 104/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0014\n",
      "Epoch 105/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0014\n",
      "Epoch 106/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0013\n",
      "Epoch 107/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0013\n",
      "Epoch 108/200\n",
      "38/38 [==============================] - 3s 70ms/step - loss: 0.0015\n",
      "Epoch 109/200\n",
      "38/38 [==============================] - 3s 73ms/step - loss: 0.0015\n",
      "Epoch 110/200\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.0014\n",
      "Epoch 111/200\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.0014\n",
      "Epoch 112/200\n",
      "38/38 [==============================] - 3s 68ms/step - loss: 0.0013\n",
      "Epoch 113/200\n",
      "38/38 [==============================] - 2s 58ms/step - loss: 0.0012\n",
      "Epoch 114/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0013\n",
      "Epoch 115/200\n",
      "38/38 [==============================] - 2s 58ms/step - loss: 0.0013\n",
      "Epoch 116/200\n",
      "38/38 [==============================] - 2s 60ms/step - loss: 0.0014\n",
      "Epoch 117/200\n",
      "38/38 [==============================] - 3s 69ms/step - loss: 0.0012\n",
      "Epoch 118/200\n",
      "38/38 [==============================] - 2s 58ms/step - loss: 0.0012\n",
      "Epoch 119/200\n",
      "38/38 [==============================] - 2s 58ms/step - loss: 0.0016\n",
      "Epoch 120/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0013\n",
      "Epoch 121/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0013\n",
      "Epoch 122/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0013\n",
      "Epoch 123/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0014\n",
      "Epoch 124/200\n",
      "38/38 [==============================] - 3s 75ms/step - loss: 0.0013\n",
      "Epoch 125/200\n",
      "38/38 [==============================] - 2s 62ms/step - loss: 0.0012\n",
      "Epoch 126/200\n",
      "38/38 [==============================] - 2s 59ms/step - loss: 0.0011\n",
      "Epoch 127/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0012\n",
      "Epoch 128/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0012\n",
      "Epoch 129/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0012\n",
      "Epoch 130/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0011\n",
      "Epoch 131/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0012\n",
      "Epoch 132/200\n",
      "38/38 [==============================] - 2s 61ms/step - loss: 0.0012\n",
      "Epoch 133/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0013\n",
      "Epoch 134/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0012\n",
      "Epoch 135/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0012\n",
      "Epoch 136/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0011\n",
      "Epoch 137/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0012\n",
      "Epoch 138/200\n",
      "38/38 [==============================] - 2s 59ms/step - loss: 0.0011\n",
      "Epoch 139/200\n",
      "38/38 [==============================] - 3s 81ms/step - loss: 0.0011\n",
      "Epoch 140/200\n",
      "38/38 [==============================] - 2s 59ms/step - loss: 0.0011\n",
      "Epoch 141/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0012\n",
      "Epoch 142/200\n",
      "38/38 [==============================] - 2s 62ms/step - loss: 0.0012\n",
      "Epoch 143/200\n",
      "38/38 [==============================] - 2s 65ms/step - loss: 0.0011\n",
      "Epoch 144/200\n",
      "38/38 [==============================] - 2s 61ms/step - loss: 0.0012\n",
      "Epoch 145/200\n",
      "38/38 [==============================] - 2s 61ms/step - loss: 0.0013\n",
      "Epoch 146/200\n",
      "38/38 [==============================] - 2s 60ms/step - loss: 0.0013\n",
      "Epoch 147/200\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.0011\n",
      "Epoch 148/200\n",
      "38/38 [==============================] - 2s 60ms/step - loss: 0.0013\n",
      "Epoch 149/200\n",
      "38/38 [==============================] - 2s 63ms/step - loss: 0.0012\n",
      "Epoch 150/200\n",
      "38/38 [==============================] - 3s 72ms/step - loss: 0.0011\n",
      "Epoch 151/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 152/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0010\n",
      "Epoch 153/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 9.9097e-04\n",
      "Epoch 154/200\n",
      "38/38 [==============================] - 2s 59ms/step - loss: 0.0012\n",
      "Epoch 155/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0013\n",
      "Epoch 156/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 157/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 158/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 159/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 160/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0013\n",
      "Epoch 161/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 162/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 163/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0017\n",
      "Epoch 164/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0010\n",
      "Epoch 165/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 166/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 167/200\n",
      "38/38 [==============================] - 2s 57ms/step - loss: 0.0011\n",
      "Epoch 168/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 169/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 170/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 9.4637e-04\n",
      "Epoch 171/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 172/200\n",
      "38/38 [==============================] - 2s 52ms/step - loss: 0.0011\n",
      "Epoch 173/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 174/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0010\n",
      "Epoch 175/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0011\n",
      "Epoch 176/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0010\n",
      "Epoch 177/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 0.0012\n",
      "Epoch 178/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 179/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 9.4830e-04\n",
      "Epoch 180/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 9.7374e-04\n",
      "Epoch 181/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 182/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 9.5923e-04\n",
      "Epoch 183/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 184/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 9.7606e-04\n",
      "Epoch 185/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0011\n",
      "Epoch 186/200\n",
      "38/38 [==============================] - 2s 55ms/step - loss: 9.2077e-04\n",
      "Epoch 187/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0012\n",
      "Epoch 188/200\n",
      "38/38 [==============================] - 3s 71ms/step - loss: 0.0012\n",
      "Epoch 189/200\n",
      "38/38 [==============================] - 3s 70ms/step - loss: 0.0011\n",
      "Epoch 190/200\n",
      "38/38 [==============================] - 2s 61ms/step - loss: 9.4316e-04\n",
      "Epoch 191/200\n",
      "38/38 [==============================] - 2s 56ms/step - loss: 0.0012\n",
      "Epoch 192/200\n",
      "38/38 [==============================] - 3s 70ms/step - loss: 0.0012\n",
      "Epoch 193/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 9.5740e-04\n",
      "Epoch 194/200\n",
      "38/38 [==============================] - 2s 59ms/step - loss: 9.5650e-04\n",
      "Epoch 195/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 9.8898e-04\n",
      "Epoch 196/200\n",
      "38/38 [==============================] - 2s 53ms/step - loss: 0.0011\n",
      "Epoch 197/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 0.0011\n",
      "Epoch 198/200\n",
      "38/38 [==============================] - 2s 61ms/step - loss: 9.4725e-04\n",
      "Epoch 199/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 2s 56ms/step - loss: 9.0135e-04\n",
      "Epoch 200/200\n",
      "38/38 [==============================] - 2s 54ms/step - loss: 9.4089e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a0f3203a60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to the Training set\n",
    "# 'X_train' Independent variables\n",
    "# 'y_train' Output Truths that we compare X_train to.\n",
    "regressor.fit(X_train, y_train, epochs = 200, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hRau_lIkrE8"
   },
   "source": [
    "## Part 3 - Making the predictions and visualising the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgJO6qEDksxD"
   },
   "source": [
    "### Getting the real stock price of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "FmBT2zqukxTz"
   },
   "outputs": [],
   "source": [
    "# Getting the real stock price of 2017\n",
    "dataset_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "real_stock_price = dataset_test.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrvrLblxkz42"
   },
   "source": [
    "### Getting the predicted stock price of 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "emikTvUpk3Ck"
   },
   "outputs": [],
   "source": [
    "# Getting the predicted stock price of 2017\n",
    "# We need 60 previous inputs for each day of the Test_set in 2017\n",
    "# Combine 'dataset_train' and 'dataset_test'\n",
    "# 'axis = 0' for Vertical Concatenation to add rows to the bottom\n",
    "dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis = 0)\n",
    "# Extract Stock Prices for Test time period, plus 60 days previous\n",
    "inputs = dataset_total[len(dataset_total) - len(dataset_test) - 60:].values\n",
    "# 'reshape' function to get it into a NumPy format\n",
    "inputs = inputs.reshape(-1,1)\n",
    "# Inputs need to be scaled to match the model trained on Scaled Feature\n",
    "inputs = sc.transform(inputs)\n",
    "# The following is pasted from above and modified for Testing, romove all 'Ys'\n",
    "X_test = []\n",
    "\n",
    "for i in range(60, 80):\n",
    "    X_test.append(inputs[i-60:i, 0])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "# We need a 3D input so add another dimension\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# Predict the Stock Price\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "# We need to inverse the scaling of our prediction to get a Dollar amount\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFTNs3YHk6FQ"
   },
   "source": [
    "### Visualising the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1676414788111,
     "user": {
      "displayName": "jayesh soni",
      "userId": "15631968598906199091"
     },
     "user_tz": 300
    },
    "id": "8OUI8U49k9tH"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the results\n",
    "plt.plot(real_stock_price, color = 'red', label = 'Real Google Stock Price')\n",
    "plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Google Stock Price')\n",
    "plt.title('Google Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Google Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
